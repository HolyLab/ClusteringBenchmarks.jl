var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = ClusteringBenchmarks","category":"page"},{"location":"#ClusteringBenchmarks","page":"Home","title":"ClusteringBenchmarks","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ClusteringBenchmarks.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [ClusteringBenchmarks]","category":"page"},{"location":"#ClusteringBenchmarks.ami-Tuple{AbstractMatrix{Int64}}","page":"Home","title":"ClusteringBenchmarks.ami","text":"score = ami(refclust, clust)\nscore = ami(C)\n\nCompute the Adjusted Mutual Information (AMI) of a clustering clust with respect to the \"ground truth\" refclust. Alternatively supply the contingency matrix C (see contingency_matrix).\n\nnote: Note\nAMI assumes hard-clustering.\n\nImplements Eq. 24a in:     Vinh, N.X., Epps, J. and Bailey, J., 2009. Information theoretic measures for clusterings comparison: is a correction     for chance necessary?. In Proceedings of the 26th annual international conference on machine learning (pp. 1073-1080).\n\n\n\n\n\n","category":"method"},{"location":"#ClusteringBenchmarks.contingency_matrix-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}}","page":"Home","title":"ClusteringBenchmarks.contingency_matrix","text":"C = contingency_matrix(refclust, clust)\n\nCompute the contingency matrix of a clustering clust with respect to the \"ground truth\" refclust. Both refclust and clust are vectors of cluster labels (integers).\n\nC[i, j] is the number of objects that are in cluster i in refclust and in cluster j in clust.\n\n\n\n\n\n","category":"method"},{"location":"#ClusteringBenchmarks.load_gagolewski-Tuple{Any, Any}","page":"Home","title":"ClusteringBenchmarks.load_gagolewski","text":"data, labelsets = load_gagolewski(battery, dataset)\n\nLoad a dataset from the Gagolewski collection of data sets. data is a d Ã— N matrix of Float64 values, where d is the dimensionality of the data set and N is the number of observations. labelsets is a vector of label-vectors (for each label-vector label = labelsets[i], label[j] is the cluster number assigned to the jth data point). Most data sets have a single label-vector, but some provide multiple label sets. Typically the first is the one provided by the original creator of the data set, and is the recommended choice for benchmarking.\n\nExamples\n\nusing ClusteringBenchmarks\ndata, labelsets = load_gagolewski(\"wut\", \"x2\")\n\n\n\n\n\n","category":"method"},{"location":"#ClusteringBenchmarks.nca-Tuple{AbstractMatrix{Int64}}","page":"Home","title":"ClusteringBenchmarks.nca","text":"score = nca(refclust, clust)\nscore = nca(C)\n\nCompute the Normalised Clustering Accuracy (NCA) of a clustering clust with respect to the \"ground truth\" refclust. Alternatively supply the contingency matrix C (see contingency_matrix).\n\nnote: Note\nThe NCA assumes hard-clustering and requires that the number of clusters in refclust and clust be the same (C must be square). It scales poorly when there are many (>20) clusters.\n\nImplements Eq 35 in:     Gagolewski, M. (2023). Normalised clustering accuracy: An asymmetric external cluster validity measure (preprint).     URL: https://arxiv.org/pdf/2209.02935.pdf, DOI: 10.48550/arXiv.2209.02935\n\n\n\n\n\n","category":"method"}]
}
